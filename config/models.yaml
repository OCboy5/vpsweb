# Vox Poetica Model Registry - Pure model information
# Simplified structure: providers + models + pricing (no task-specific configs)

providers:
  tongyi:
    api_key_env: "TONGYI_API_KEY"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    type: "openai_compatible"

  deepseek:
    api_key_env: "DEEPSEEK_API_KEY"
    base_url: "https://api.deepseek.com"
    type: "openai_compatible"

  siliconflow:
    api_key_env: "SILICONFLOW_API_KEY"
    base_url: "https://api.siliconflow.cn/v1/"
    type: "openai_compatible"
  
  moonshot:
    api_key_env: "MOONSHOT_API_KEY"
    base_url: "https://api.moonshot.cn/v1"
    type: "openai_compatible"

models:
  qwen3_max:
    provider: "tongyi"
    name: "qwen3-max"
    reasoning: false
    description: "High-quality general purpose model for complex translations"

  qwen3_plus:
    provider: "tongyi"
    name: "qwen-plus-latest"
    reasoning: false
    description: "Fast and efficient non-reasoning translation model"

  deepseek_reasoner:
    provider: "deepseek"
    name: "deepseek-reasoner"
    reasoning: true
    description: "Advanced reasoning model for complex translation tasks"

  deepseek_chat:
    provider: "deepseek"
    name: "deepseek-chat"
    reasoning: false
    description: "General purpose chat model for translation"

  kimi_k2:
    provider: "moonshot"
    name: "kimi-k2-0905-preview"
    reasoning: false
    description: "Latest non-reasoning moodel from Moonshot"

  kimi_k2_thinking:
    provider: "moonshot"
    name: "kimi-k2-thinking"
    reasoning: true
    description: "Latest reasoning model via SiliconFlow"

  deepseek_v32_silicon:
    provider: "siliconflow"
    name: "deepseek-ai/DeepSeek-V3.2-Exp"
    reasoning: true
    description: "Latest reasoning model via SiliconFlow"

  kimi_k2_thinking_silicon:
    provider: "siliconflow"
    name: "moonshotai/Kimi-K2-Thinking"
    reasoning: true
    description: "Latest reasoning model via SiliconFlow"

  kimi_k2_thinking_turbo_silicon:
    provider: "siliconflow"
    name: "moonshotai/Kimi-K2-Thinking-Turbo"
    reasoning: true
    description: "Latest reasoning model via SiliconFlow"

pricing:
  qwen3_max:
    input: 0.0032   # RMB per 1K tokens
    output: 0.0128
  qwen3_plus:
    input: 0.0008
    output: 0.002
  deepseek_reasoner:
    input: 0.002
    output: 0.003
  deepseek_chat:
    input: 0.002
    output: 0.003
  kimi_k2:
    input: 0.004
    output: 0.016
  kimi_k2_thinking:
    input: 0.004
    output: 0.016
  deepseek_v32_silicon:
    input: 0.002
    output: 0.003
  kimi_k2_thinking_silicon:
    input: 0.004
    output: 0.016
  kimi_k2_thinking_turbo_silicon:
    input: 0.004
    output: 0.016      

# Global provider settings (inherited by all providers)
provider_settings:
  timeout: 180.0
  max_retries: 3
  retry_delay: 1.0
  request_timeout: 30.0
  connection_pool_size: 10

# Reasoning model specific settings (inherited by all reasoning models)
reasoning_settings:
  timeout: 600.0              # Extended for reasoning time
  max_retries: 2              # Fewer retries (expensive)
  request_timeout: 300.0       # Longer individual requests